{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a06dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import shutil\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e17bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_TO_PROCESS = ['VIVIR', 'ALGUNO', 'DIABETES', 'GORDO', 'RESULTADO']\n",
    "SKIP_SIGNER = 4\n",
    "\n",
    "NOVELTY_BASE = '/home/gerardo/NoveltyDetection'\n",
    "SUB_FOLDER = '-1'\n",
    "NOVELTY_DIR = os.path.join(NOVELTY_BASE, SUB_FOLDER)\n",
    "\n",
    "os.makedirs(NOVELTY_DIR, exist_ok=True)\n",
    "\n",
    "dfs = pd.read_excel(\n",
    "    '/home/gerardo/LSE_HEALTH/LSE-Health-UVigo.xlsx',\n",
    "    sheet_name=None\n",
    ")\n",
    "GlossesContent = dfs['GlossesContent']\n",
    "\n",
    "def extract_words_from_json(json_file_path):\n",
    "    basename = os.path.basename(json_file_path)\n",
    "    match = re.search(r'_(\\d+)(?=\\.json)', basename)\n",
    "    if not match:\n",
    "        return\n",
    "\n",
    "    signer = int(match.group(1))\n",
    "    if signer == SKIP_SIGNER:\n",
    "        return\n",
    "\n",
    "    video = re.sub(r'_[0-9]+\\.json$', '', basename)\n",
    "\n",
    "    fps = 25\n",
    "\n",
    "    with open(json_file_path, 'r') as jf:\n",
    "        data = json.load(jf)\n",
    "\n",
    "    for word in WORDS_TO_PROCESS:\n",
    "\n",
    "        elan_filtered = GlossesContent.loc[\n",
    "            (GlossesContent['File'] == video) &\n",
    "            (GlossesContent['Gloss'] == word)\n",
    "        ]\n",
    "        if elan_filtered.empty:\n",
    "            continue\n",
    "\n",
    "        for _, row in elan_filtered.iterrows():\n",
    "            start_ms = row['Start(ms)']\n",
    "            end_ms = row['End(ms)']\n",
    "            start_frame = int(start_ms / 1000 * fps)\n",
    "            end_frame = int(end_ms / 1000 * fps)\n",
    "\n",
    "            filtered_frames = [f for f in data if start_frame <= f['frame'] <= end_frame]\n",
    "\n",
    "            word_data = {\n",
    "                'signer': signer,\n",
    "                'video': video,\n",
    "                'gloss': word,\n",
    "                'start': start_ms,\n",
    "                'end': end_ms,\n",
    "                'frames': filtered_frames\n",
    "            }\n",
    "\n",
    "            out_name = f\"{word}_{video}_{signer}_{start_ms}_{end_ms}.json\"\n",
    "            out_path = os.path.join(NOVELTY_DIR, out_name)\n",
    "            with open(out_path, 'w') as out_f:\n",
    "                json.dump(word_data, out_f)\n",
    "\n",
    "base_path = '/home/gerardo/LSE_DATABASE/LSE_HEALTH'\n",
    "for fname in os.listdir(base_path):\n",
    "    if fname.lower().endswith('.json'):\n",
    "        extract_words_from_json(os.path.join(base_path, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ccc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    if p1[0] == -1 and p1[1] == -1:\n",
    "        return -1\n",
    "    if p2[0] == -1 and p2[1] == -1:\n",
    "        return -1\n",
    "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(p1, p2)))\n",
    "\n",
    "def angle_between_joints(a, b, c):\n",
    "    ba = np.array(a) - np.array(b)\n",
    "    bc = np.array(c) - np.array(b)\n",
    "    cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    return np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849a1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hand_missing(landmarks):\n",
    "    for lm in landmarks:\n",
    "        if not (lm['x'] == -1 and lm['y'] == -1 and lm['z'] == -1):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def extract_pose_landmarks(pose_landmarks, row, prefix='pose'):\n",
    "    left_labels = ['LEFT_ANKLE', 'LEFT_FOOT_INDEX', 'LEFT_HEEL', 'LEFT_INDEX', 'LEFT_KNEE', 'LEFT_PINKY', 'LEFT_THUMB', 'LEFT_WRIST']\n",
    "    right_labels = ['RIGHT_ANKLE', 'RIGHT_FOOT_INDEX', 'RIGHT_HEEL', 'RIGHT_INDEX', 'RIGHT_KNEE', 'RIGHT_PINKY', 'RIGHT_THUMB', 'RIGHT_WRIST']\n",
    "    face = ['LEFT_EYE_INNER', 'RIGHT_EYE_INNER','LEFT_EYE_OUTER', 'RIGHT_EYE_OUTER','RIGHT_EYE', 'LEFT_EYE','LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT']\n",
    "\n",
    "    for lm in pose_landmarks:\n",
    "        if lm['label'] not in left_labels and lm['label'] not in right_labels and lm['label'] not in face:\n",
    "            label = lm['label']\n",
    "            row[f'{prefix}.{label}_x'] = lm['x']\n",
    "            row[f'{prefix}.{label}_y'] = lm['y']\n",
    "            row[f'{prefix}.{label}_z'] = lm['z']\n",
    "    return row\n",
    "\n",
    "def extract_hand_landmarks(hand_data, row, hand_name='Hand_0'):\n",
    "    excluded_labels = {\n",
    "        \"INDEX_FINGER_DIP\", \"INDEX_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_PIP\",\n",
    "        \"PINKY_DIP\", \"PINKY_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_PIP\",\n",
    "        \"THUMB_CMC\", \"THUMB_IP\"\n",
    "    }\n",
    "\n",
    "    for lm in hand_data['landmarks']:\n",
    "        label = lm['label']\n",
    "        if label in excluded_labels:\n",
    "            continue\n",
    "        if is_hand_missing(hand_data['landmarks']):\n",
    "            row[f'{hand_name}.{label}_x'] = -1\n",
    "            row[f'{hand_name}.{label}_y'] = -1\n",
    "            row[f'{hand_name}.{label}_z'] = -1\n",
    "        else:\n",
    "            row[f'{hand_name}.{label}_x'] = lm['x']\n",
    "            row[f'{hand_name}.{label}_y'] = lm['y']\n",
    "            row[f'{hand_name}.{label}_z'] = lm['z']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adccfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        frames = data\n",
    "    elif isinstance(data, dict) and 'frames' in data:\n",
    "        frames = data['frames']\n",
    "    else:\n",
    "        print(\"Formato JSON no reconocido.\")\n",
    "        return\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No se encontraron fotogramas en el JSON.\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    for frame_info in frames:\n",
    "        row = {'frame': frame_info.get('frame', -1)}\n",
    "        row = extract_pose_landmarks(frame_info.get('pose_landmarks', []), row)\n",
    "        for hand in frame_info.get('hand_landmarks', []):\n",
    "            row = extract_hand_landmarks(hand, row, hand_name=hand['hand'])\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.sort_values(by='frame', inplace=True)\n",
    "    df.interpolate(method='linear', limit_direction='both', inplace=True)\n",
    "    df.fillna(-1, inplace=True)\n",
    "\n",
    "    fieldnames = list(df.columns)\n",
    "    fieldnames.remove('frame')\n",
    "    fieldnames = ['frame'] + sorted(fieldnames)\n",
    "    df = df[fieldnames]\n",
    "\n",
    "    output_csv = json_file.replace('.json', '.csv')\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"CSV generado con interpolaciÃ³n en: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2762fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_distances(dict_coords):\n",
    "    distances = {}\n",
    "\n",
    "    distances['Nose-Left_Shoulder'] = euclidean_distance(dict_coords['pose.NOSE'], dict_coords['pose.LEFT_SHOULDER'])\n",
    "    distances['Nose-Right_Shoulder'] = euclidean_distance(dict_coords['pose.NOSE'], dict_coords['pose.RIGHT_SHOULDER'])\n",
    "\n",
    "    distances['Nose-Left_WRIST'] = euclidean_distance(dict_coords['pose.NOSE'], dict_coords['Hand_0.WRIST'])\n",
    "    distances['Nose-Right_WRIST'] = euclidean_distance(dict_coords['pose.NOSE'], dict_coords['Hand_1.WRIST'])\n",
    "\n",
    "    distances['Left_Shoulder-Left_WRIST'] = euclidean_distance(dict_coords['pose.LEFT_SHOULDER'], dict_coords['Hand_0.WRIST'])\n",
    "    distances['Right_Shoulder-Right_WRIST'] = euclidean_distance(dict_coords['pose.RIGHT_SHOULDER'], dict_coords['Hand_1.WRIST'])\n",
    "    distances['Left_WRIST-Right_WRIST'] = euclidean_distance(dict_coords['Hand_0.WRIST'], dict_coords['Hand_1.WRIST'])\n",
    "\n",
    "    fingers = ['THUMB', 'INDEX_FINGER', 'MIDDLE_FINGER', 'RING_FINGER', 'PINKY']\n",
    "    for f in fingers:\n",
    "        distances[f'Hand_0.{f}_Tip-Mcp'] = euclidean_distance(dict_coords[f'Hand_0.{f}_TIP'], dict_coords[f'Hand_0.{f}_MCP'])\n",
    "        distances[f'Hand_1.{f}_Tip-Mcp'] = euclidean_distance(dict_coords[f'Hand_1.{f}_TIP'], dict_coords[f'Hand_1.{f}_MCP'])\n",
    "\n",
    "    for f1, f2 in combinations(fingers, 2):\n",
    "        distances[f'Hand_0.{f1}_Tip-Hand_0.{f2}_Tip'] = euclidean_distance(dict_coords[f'Hand_0.{f1}_TIP'], dict_coords[f'Hand_0.{f2}_TIP'])\n",
    "        distances[f'Hand_1.{f1}_Tip-Hand_1.{f2}_Tip'] = euclidean_distance(dict_coords[f'Hand_1.{f1}_TIP'], dict_coords[f'Hand_1.{f2}_TIP'])\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efb0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(input_dir, output_dir, clean_output_dir=True):\n",
    "    if os.path.exists(output_dir):\n",
    "        if clean_output_dir:\n",
    "            shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"Directory {output_dir} created\")\n",
    "\n",
    "    for subfolder in os.listdir(input_dir):\n",
    "        subfolder_path = os.path.join(input_dir, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        output_subfolder_path = os.path.join(output_dir, subfolder)\n",
    "        os.makedirs(output_subfolder_path, exist_ok=True)\n",
    "\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            if not file.endswith('.csv') or file.endswith('_features.csv'):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(subfolder_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            output_rows = []\n",
    "            l = df.columns[1:]\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                dict_coords = {'frame': row['frame']}\n",
    "                for i in range(0, len(l), 3):\n",
    "                    name = l[i].split('_x')[0]\n",
    "                    dict_coords[name] = (row[l[i]], row[l[i+1]], row[l[i+2]])\n",
    "\n",
    "                d1 = euclidean_distance(dict_coords['pose.LEFT_HIP'], dict_coords['pose.LEFT_SHOULDER'])\n",
    "                d2 = euclidean_distance(dict_coords['pose.RIGHT_HIP'], dict_coords['pose.RIGHT_SHOULDER'])\n",
    "                height_percentage = ((d1 + d2) / 2) * 0.265\n",
    "\n",
    "                distances = pose_distances(dict_coords)\n",
    "\n",
    "                for k in distances:\n",
    "                    distances[k] = distances[k] / height_percentage\n",
    "\n",
    "                frame_data = {'frame': row['frame'], **distances}\n",
    "                output_rows.append(frame_data)\n",
    "\n",
    "            df_out = pd.DataFrame(output_rows)\n",
    "            output_file = os.path.join(output_subfolder_path, file.replace('.csv', '_features.csv'))\n",
    "            df_out.to_csv(output_file, index=False)\n",
    "            print(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c6642ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_directory(path):\n",
    "    for subfolder in os.listdir(path):\n",
    "        subfolder_path = os.path.join(path, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        for json_file in os.listdir(subfolder_path):\n",
    "            if not json_file.endswith(\".json\"):\n",
    "                continue\n",
    "\n",
    "            json_file_path = os.path.join(subfolder_path, json_file)\n",
    "            json_to_csv(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963695ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_json_directory('/home/gerardo/NoveltyDetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_directory('/home/gerardo/NoveltyDetection', '/home/gerardo/NoveltyDetectionProcessed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSE_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
