{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c1c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_processing.pose_features.utils import euclidean_distance\n",
    "from data_processing.pose_features.pose_geometry import pose_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab81b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_content = pd.read_excel('/home/gerardo/LSE_HEALTH/LSE-Health-UVigo.xlsx', sheet_name='SegmentsContent')\n",
    "glosses_content = pd.read_excel('/home/gerardo/LSE_HEALTH/LSE-Health-UVigo.xlsx', sheet_name='GlossesContent')\n",
    "\n",
    "signer_video = pd.read_excel('/home/gerardo/LSE_HEALTH/LSE_TFG/video_processing/signer_video.xlsx')\n",
    "\n",
    "labels = pd.read_csv('/home/gerardo/LSE_HEALTH/LSE_TFG/labeled_words.csv')\n",
    "\n",
    "label2code = labels.set_index(\"Word\")[\"Encoded_Label\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f712b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('/home/gerardo/LSE_SEGMENTATION_DATASET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(df):\n",
    "\n",
    "    output_rows = []\n",
    "\n",
    "    coord_cols = [c for c in df.columns if re.search(r'_(x|y|z)$', c)]\n",
    "\n",
    "    landmarks = sorted({col.rsplit('_', 1)[0] for col in coord_cols})\n",
    "\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        dict_coords = {'frame': row['frame']}\n",
    "\n",
    "\n",
    "        for name in landmarks:\n",
    "            try:\n",
    "                x = row[f'{name}_x']\n",
    "                y = row[f'{name}_y']\n",
    "                z = row[f'{name}_z']\n",
    "                dict_coords[name] = (x, y, z)\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            d1 = euclidean_distance(dict_coords['pose.LEFT_HIP'], dict_coords['pose.LEFT_SHOULDER'])\n",
    "            d2 = euclidean_distance(dict_coords['pose.RIGHT_HIP'], dict_coords['pose.RIGHT_SHOULDER'])\n",
    "            height_percentage = ((d1 + d2) / 2) * 0.265\n",
    "\n",
    "            distances = pose_distances(dict_coords)\n",
    "            for k in distances:\n",
    "                distances[k] = distances[k] / height_percentage\n",
    "\n",
    "            gesture_value = row.get('Gesture', 0)\n",
    "            frame_data = {'frame': row['frame'], 'Gesture': gesture_value, **distances}\n",
    "            output_rows.append(frame_data)\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing keypoint in frame {row['frame']}: {e}\")\n",
    "            continue\n",
    "    df_out = pd.DataFrame(output_rows)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spot_dataset = '/home/gerardo/LSE_SPOT_DATASET'\n",
    "fps = 25\n",
    "\n",
    "for file in os.listdir(path_spot_dataset):\n",
    "    if file.endswith('_4.csv'):\n",
    "        continue\n",
    "    df = pd.read_csv(os.path.join(path_spot_dataset, file))\n",
    "    video_name = re.split('_[0-9]*.csv', file)[0]\n",
    "\n",
    "    segments = segment_content[segment_content['File'] == video_name]\n",
    "    segments = segments[['Start(ms)', 'End(ms)']]\n",
    "    \n",
    "\n",
    "    glosses = glosses_content[glosses_content['File'] == video_name]\n",
    "\n",
    "    for _, segment in segments.iterrows():\n",
    "\n",
    "        glosses_per_segment = glosses.loc[\n",
    "            (glosses['Start(ms)'].between(segment['Start(ms)'], segment['End(ms)'])) &\n",
    "            (glosses['End(ms)'].between(segment['Start(ms)'], segment['End(ms)']))\n",
    "        ]\n",
    "\n",
    "        glosses_per_segment = glosses_per_segment.copy()\n",
    "\n",
    "\n",
    "        glosses_per_segment['Start(ms)'] = (glosses_per_segment['Start(ms)'] / 1000 * fps).astype(int)\n",
    "        glosses_per_segment['End(ms)']   = (glosses_per_segment['End(ms)']   / 1000 * fps).astype(int)\n",
    "        truth_frames = []\n",
    "        for _, frames in glosses_per_segment.iterrows():\n",
    "            for i in range(frames['Start(ms)'], frames['End(ms)']):\n",
    "                try:\n",
    "                    gloss = frames['Gloss'].replace('*', '')\n",
    "                    label = label2code[gloss]\n",
    "                    truth_frames.append(i)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                \n",
    "\n",
    "        start_frame = int(segment['Start(ms)'] / 1000 * fps)\n",
    "        end_frame = int(segment['End(ms)'] / 1000 * fps)\n",
    "\n",
    "        df_segment = df.loc[df['frame'].between(start_frame, end_frame)]\n",
    "\n",
    "        gesture_list = []\n",
    "        for _, frame in df_segment.iterrows():\n",
    "            if frame['frame'] in truth_frames:\n",
    "                try:\n",
    "                    gloss = glosses_per_segment.loc[\n",
    "                                (glosses_per_segment['Start(ms)'] <= frame['frame']) &\n",
    "                                (glosses_per_segment['End(ms)']   >  frame['frame'])\n",
    "                            ]['Gloss'].iloc[0].replace('*', '')\n",
    "                    label = label2code[gloss]\n",
    "                except (KeyError, IndexError):\n",
    "                    label = 43\n",
    "            else:\n",
    "                label = 43\n",
    "\n",
    "            gesture_list.append(label)\n",
    "        \n",
    "        if all(l == 43 for l in gesture_list):\n",
    "            continue\n",
    "        else:\n",
    "            df_segment = df_segment.copy()\n",
    "            df_segment['Gesture'] = gesture_list\n",
    "\n",
    "            f_df = process_file(df_segment)\n",
    "\n",
    "            f_df.to_csv(os.path.join('/home/gerardo/LSE_SEGMENTATION_DATASET',\n",
    "                                    f'{video_name}_{int(segment[\"Start(ms)\"])}_{int(segment[\"End(ms)\"])}.csv'),\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f36ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3152 files → /home/gerardo/LSE_SEGMENTATION_SPLIT/train\n",
      "val: 675 files → /home/gerardo/LSE_SEGMENTATION_SPLIT/val\n",
      "test: 677 files → /home/gerardo/LSE_SEGMENTATION_SPLIT/test\n"
     ]
    }
   ],
   "source": [
    "def downsample_by_boxes(df: pd.DataFrame, target_length: int) -> pd.DataFrame:\n",
    "    n = len(df)\n",
    "    if n <= target_length:\n",
    "        return df.reset_index(drop=True)\n",
    "    box_size = n / target_length\n",
    "    indices = [min(n-1, int(round((i + 0.5) * box_size)))\n",
    "               for i in range(target_length)]\n",
    "    return df.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "def process_file(input_path: str,\n",
    "                 output_path: str,\n",
    "                 target_gesture: int,\n",
    "                 target_len_per_run: int,\n",
    "                 gesture_col: str = 'Gesture'):\n",
    "    \"\"\"\n",
    "    Read input_path, downsample only the runs of target_gesture,\n",
    "    reassemble and write to output_path.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_path)\n",
    "    run_id = df[gesture_col].ne(df[gesture_col].shift()).cumsum()\n",
    "    processed_runs = []\n",
    "    for _, run in df.groupby(run_id):\n",
    "        if run[gesture_col].iloc[0] == target_gesture:\n",
    "            run_ds = downsample_by_boxes(run, target_len_per_run)\n",
    "        else:\n",
    "            run_ds = run.reset_index(drop=True)\n",
    "        processed_runs.append(run_ds)\n",
    "\n",
    "    df_out = pd.concat(processed_runs, ignore_index=True)\n",
    "    df_out.to_csv(output_path, index=False)\n",
    "\n",
    "def split_and_prepare(input_dir: str,\n",
    "                      output_dir: str,\n",
    "                      target_gesture: int,\n",
    "                      target_len_per_run: int,\n",
    "                      splits=(0.7, 0.15, 0.15),\n",
    "                      seed=42):\n",
    "    \"\"\"\n",
    "    Splits the CSVs in input_dir into train/val/test according to `splits`,\n",
    "    downsampling only the train set, and copies val/test untouched.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(input_dir) if f.lower().endswith('.csv')]\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(files)\n",
    "\n",
    "    n = len(files)\n",
    "    n_train = int(splits[0] * n)\n",
    "    n_val   = int(splits[1] * n)\n",
    "    train_files = files[:n_train]\n",
    "    val_files   = files[n_train:n_train + n_val]\n",
    "    test_files  = files[n_train + n_val:]\n",
    "\n",
    "    for subset, flist in (('train', train_files),\n",
    "                          ('val',   val_files),\n",
    "                          ('test',  test_files)):\n",
    "        subset_dir = os.path.join(output_dir, subset)\n",
    "        os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "        for fname in flist:\n",
    "            src = os.path.join(input_dir, fname)\n",
    "            dst = os.path.join(subset_dir, fname)\n",
    "\n",
    "            if subset == 'train':\n",
    "                process_file(src, dst,\n",
    "                             target_gesture, target_len_per_run)\n",
    "            else:\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "        print(f\"{subset}: {len(flist)} files → {subset_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_DIR          = '/home/gerardo/LSE_SEGMENTATION_DATASET'\n",
    "    OUTPUT_DIR         = '/home/gerardo/LSE_SEGMENTATION_SPLIT'\n",
    "    TARGET_GESTURE     = 43\n",
    "    TARGET_LEN_PER_RUN = 11\n",
    "\n",
    "    split_and_prepare(INPUT_DIR, OUTPUT_DIR,\n",
    "                      TARGET_GESTURE, TARGET_LEN_PER_RUN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSE_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
